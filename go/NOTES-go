? IStorage.Load -> per storage connection

? random access -> mmap

- scheduler won't use free P if a G is taking time and other Gs are queued after it on the same P:
   https://groups.google.com/forum/#!topic/golang-nuts/8KYER1ALelg

e870f06c (runtime: yield time slice to most recently readied G)
ea0386f8 (runtime: improve randomized stealing logic)
4bb491b1 (runtime: improve scheduler fairness)
bc31bccc (runtime: preempt long-running goroutines)
179d41fe (runtime: tune P retake logic)
fb6f8a96 (runtime: remove unnecessary wakeups of worker threads)
/s steal
findrunnable
runqsteal
? runqgrab
schedule	<- top entry
868c8b37 (runtime: only sleep before stealing work from a running P)
b75b4d0e (runtime: skip netpoll check if there are no waiters)


-> stopm()	// stop and restart m after waiting for work
	notesleep(m.park)
	notewakeup

   startm()	(calls notewakeup(m.park)
 ? wakep()	(calls startm(nil, ...)
 ? startlockedm

https://golang.org/s/go11sched	-> syscall/M partking and Unparking/Spinning
runtime/HACKING.md

----------------------------------------

- TODO stats for events (packets received, errors, etc)

- custom memory manager is required to avoid performance hit on e.g. []byte alloc/dealloc

  -> go-slab

- interfaces conversion in hot codepaths are costly:

  e.g. having r as io.ReadSeeker and converting it to io.Reader e.g. this way:


	io.ReadFull(r, ...)

  calls convI2I all the time (no caching) which is not negliable



- x/net/trace to trace requests and connection logging (and packets ?)
- packet log; general log -> glog ?

  -> http://opentracing.io/

- gRPC eventually instead of hand-made protocol ?

go.leveldb      - study
go.groupcache   - study

groupcache -> consistenthash (-> fork-splitted)
